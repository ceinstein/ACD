from stop_words import get_stop_words
from nltk.tokenize import RegexpTokenizer
from nltk.stem.porter import PorterStemmer

#Loads a log and does some preprocessing on the log entries
def loadLog(filename):
	if filename.endswith('.log'):
		tokenizer = RegexpTokenizer(r'\w+')
		en_stop = get_stop_words('en')
		stemmer = PorterStemmer()
		file = open(filename, 'r')
		log = []
		for line in file:
			tokens = tokenizer.tokenize(line.decode('utf-8').lower()) #Tokenizes the line
			stop_tokens = [i for i in tokens if not i in en_stop] #Removes common words
			stem_tokens = [i for i in tokens if not i in en_stop and i.isalnum()] #Stems each word
			alnum = [i for i in stem_tokens if len(i) > 1] #Removes non-alphanumeric words and single letter words
			processed = []
			#if(len(alnum) > 0):
			log.append(alnum)	
		print "Log", filename, "loaded"
		return log
	else:
		raise IOError

#Saves a parsed log
def saveLog(filename, log):
	file = open(filename, 'w')
	file.write(str(len(log)) + '\n')
	for line in log:
		for word in line:
			try:
				file.write(str(word).encode('utf8') + ' ')
			except Exception as E:
				print E, word.encode('utf8')
				exit(1)
		file.write('\n')
	print 'Log saved to', filename

#Loads a dictionary
def loadDictionary(filename):
	if filename.endswith('.dict'):
		file = open(filename, 'r')
		dictionary = []
		logLen = long(file.readline())
		for line in file:
			dictionary.append(line.strip().split()[1])
		print 'Dictionary', filename, 'loaded'
		return dictionary
	else:
		raise IOError

#Saves a dictionary 
def saveDictionary(filename, dictionary):
	file = open(filename, 'w')
	file.write(str(len(dictionary)) + '\n')
	for i in range(len(dictionary)):
		file.write(str(i) + '\t' + str(dictionary[i]) + '\n')
	print 'Dictionary saved to', filename

#Loads a matrix
def loadMatrix(filename):
	if filename.endswith('.matrix') or filename.endswith('.smatrix'):
		file = open(filename, 'r')
		lengths = file.readline().strip().split()
		matrix = [[0 for j in range(long(lengths[1]))]for i in range(long(lengths[0]))]
		for i in range(len(matrix)):
			line = file.readline().strip().split()
			for j in range(len(matrix[i])):
				matrix[i][j] = float(line[j])

		print 'Matrix', filename, 'loaded'
		return matrix
	else:
		raise IOError

#Saves the matrix
def saveMatrix(filename, matrix):
	file = open(filename, 'w')
	rows = len(matrix)
	columns = len(matrix[0])
	file.write(str(rows) + ' ' + str(columns) + '\n')
	for i in range(len(matrix)):
		for j in range(len(matrix[i])):
			file.write(str(matrix[i][j]) + ' ')
		file.write('\n')
	print 'Matrix saved to', filename

#Loads the labesl of a KMean calculation
def loadLabels(filename):
	if filename.endswith('.lbls'):
		file = open(filename, 'r')
		print 'Labels loaded from', filename
	 	return file.readline().split()
	else:
		raise IOError

#Saves the labels of the KMean calculation
def saveLabels(labels, filename):
	file = open(filename, 'w')
	for label in labels:
		file.write(str(label) + ' ')
	print 'Labels saved to', filename

#Saves generated clusters
def saveClusters(clusters, filename):
	file = open(filename, 'w')
	for i in range(len(clusters)):
		for j in range(len(clusters[i])):
			file.write(str(clusters[i][j]) + ' ')
		file.write('\n')
	print 'Clusters saved to', filename
#Loads the clusters generated by the ACD algorithm
#Each cluster contains log indicies and are seperated by a line
def loadClusters(filename):
	file = open(filename, 'r')
	clusters = [[]]
	for line in file:
		line = line.split()
		temp = []
		for log in line:
			temp.append(int(log))
		clusters.append(temp)
	clusters = [x for x in clusters if x != []]
	print 'Clusters loaded from', filename
	return clusters

#Saves the topics of the log
def saveTopics(filename, topics):
	file = open(filename, 'w')
	file.write(str(len(topics)) + '\n')
	for topic in topics:
		file.write(str(topic) + '\n')
	print 'Topics saved to', filename